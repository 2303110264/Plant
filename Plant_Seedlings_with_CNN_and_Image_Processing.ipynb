{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303110264/Plant/blob/main/Plant_Seedlings_with_CNN_and_Image_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TzNbM-5fkHTp",
        "outputId": "e922140d-c44d-4039-c125-9c4c28176e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'plantrecomodels:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F12280%2F17561%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240615%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240615T062251Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D56354e8de89dc80a94c31b32c9257baf633491d8f4743d125b369875e94269190724ab9173000802d464586904d56760d3f20039ade9e788ad4f8ea97c17da9aae211423423a0feb4fd5a8fee27cd44244019d2089cc76d4885712901c4de46bc4acc694ebe853178dab627ab85f3fb91790a0a092adcf7bfeb85f5152afa9eea2b97a111c0e557ea478da1e461ab2eed5ecbdee4cbb358f1875fe84a6c9c6a92b57949c1be470e05511fb16a2a0d5ed4faaff3894965c2ed62444b395edfcd8243ca4186103836bd141617869b8af4463953550d9b6bee7604381b5cb6d54fd263507de0273af2ba58c7ca882943542558711d4ed6985fc496a2ec2158965d9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "w25Wn5LSkC7T"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "_cell_guid": "e83a8430-f7d6-49e6-b55a-f605805c6fde",
        "_uuid": "56d3ea1a8bb1ee742ea817ee82b64d744a84cb57",
        "id": "Rb6Wjl99kC7V"
      },
      "cell_type": "markdown",
      "source": [
        "# Plant seedling recognition\n",
        "\n",
        "Classification process will consist of next steps:\n",
        "1. [Get data](#section1) — reading of images and labels\n",
        "2. [Cleaning data](#section2) — removing of image background, input normalization and label preparatin\n",
        "3. [Model](#section3) — creating training and validation sets, creating and fitting model\n",
        "4. [Evaluate model](#section4) — evaluation of model, make prediction\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ba57c7b2-6a8f-46c3-b88a-39c8badb6e61",
        "_uuid": "07e1cb3d84872e645e865fe1d38dcbe5bec6bca4",
        "id": "h3QHZ_qeYzSP"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='section1'></a>\n",
        "## 1. Get data\n",
        "\n",
        "Obtaining images and resizing to 70 x 70 px. We use a 70 x 70 px size for a quicker training of model. Also here we get image labels from folder name"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "cf48a187-a9b9-4767-9995-530f4042f2ef",
        "_uuid": "3d8330361f41b90be1556a5333ae562fe3103ee9",
        "id": "dkuI17C4YzSP",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "ScaleTo = 70  # px to scale\n",
        "seed = 7  # fixing random\n",
        "\n",
        "path = '../input/plant-seedlings-classification/train/*/*.png'\n",
        "files = glob(path)\n",
        "\n",
        "trainImg = []\n",
        "trainLabel = []\n",
        "j = 1\n",
        "num = len(files)\n",
        "\n",
        "# Obtain images and resizing, obtain labels\n",
        "for img in files:\n",
        "    print(str(j) + \"/\" + str(num), end=\"\\r\")\n",
        "    trainImg.append(cv2.resize(cv2.imread(img), (ScaleTo, ScaleTo)))  # Get image (with resizing)\n",
        "    trainLabel.append(img.split('/')[-2])  # Get image label (folder name)\n",
        "    j += 1\n",
        "\n",
        "trainImg = np.asarray(trainImg)  # Train images set\n",
        "trainLabel = pd.DataFrame(trainLabel)  # Train labels set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "da1b2625-138a-4ca7-97fc-7ac74d883b4d",
        "_uuid": "e5a77340c42fa54e4ab7bc2174d6fccae8777a9d",
        "id": "zm_fToNnkC7W"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at some examples of plant photos"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ac427863-563e-47c1-9741-462e4da7a774",
        "_uuid": "41f4551cf7c83b58d1606c80e9fe1fc787eb7757",
        "trusted": true,
        "id": "iJ0dxYgNkC7X"
      },
      "cell_type": "code",
      "source": [
        "# Show some example images\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(trainImg[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f36467af-e389-4064-b353-66aecb06d5ec",
        "_uuid": "84bc37d6c27d3efaf93383d800b4272b7f71e18e",
        "id": "weG9v72ikC7X"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see, every photo of plant seedling has an background, so let's try to remove it. It'll help us to goal better model accuracy"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "3fc90485-e2b4-456c-9958-ed1253db5a79",
        "_uuid": "0d7d83e4b71d5e4ef8a0b565afb369f4fa772120",
        "id": "gnLUeAThYzSU"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='section2'></a>\n",
        "## 2. Cleaning data\n",
        "\n",
        "For removing the background, we'll use the fact, that all plants on our photos are green. We can create a mask, which will leave some range of green color and remove other part of image.\n",
        "\n",
        "### 2.1. Masking green plant\n",
        "For creating mask, which will remove background, we need to convert RGB image to HSV. HSV is alternative of the RGB color model. In HSV, it is easier to represent a color range than in RGB color space.\n",
        "\n",
        "![HSV color model](https://codewords.recurse.com/images/six/image-processing-101/hsv.png)\n",
        "\n",
        "Besides of this, we'll blur image firstly for removing noise. After creating HSV image, we'll create mask based on empirically selected range of green color, convert it to boolean mask and apply it to the origin image.\n",
        "\n",
        "* Use gaussian blur for remove noise\n",
        "* Convert color to HSV\n",
        "* Create mask\n",
        "* Create boolean mask\n",
        "* Apply boolean mask and getting image whithout background"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "8e21f534-f0f7-4bb6-85c3-9a9c8be3cd5e",
        "_uuid": "c861144e23c2102f47885c83e4b4fde7a99cd043",
        "id": "UlXr1HtLYzSV",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "clearTrainImg = []\n",
        "examples = []; getEx = True\n",
        "for img in trainImg:\n",
        "    # Use gaussian blur\n",
        "    blurImg = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "    # Convert to HSV image\n",
        "    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Create mask (parameters - green color range)\n",
        "    lower_green = (25, 40, 50)\n",
        "    upper_green = (75, 255, 255)\n",
        "    mask = cv2.inRange(hsvImg, lower_green, upper_green)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Create bool mask\n",
        "    bMask = mask > 0\n",
        "\n",
        "    # Apply the mask\n",
        "    clear = np.zeros_like(img, np.uint8)  # Create empty image\n",
        "    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n",
        "\n",
        "    clearTrainImg.append(clear)  # Append image without backgroung\n",
        "\n",
        "    # Show examples\n",
        "    if getEx:\n",
        "        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n",
        "        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image\n",
        "        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image\n",
        "        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n",
        "        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n",
        "        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n",
        "        getEx = False\n",
        "\n",
        "clearTrainImg = np.asarray(clearTrainImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fd15895c-0609-490d-8646-48d17818bc84",
        "_uuid": "c7a2b717ac1ece011e03a9da2f07c00635c07987",
        "id": "fVSIqNrtkC7X"
      },
      "cell_type": "markdown",
      "source": [
        "Good result! Let's look at other examples of masked images"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a3e52696-bac1-40ff-b8d7-edf8a0bf40ce",
        "_uuid": "18ab5c64f074fb5ee8ce4dceeea467fae116ba0d",
        "id": "W5gQorjqYzSe",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Show sample result\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(clearTrainImg[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "56758b6c-ad98-4aba-8a20-1f320b457c86",
        "_uuid": "834fbde96ade12ac339d30cf4b2e7bb1ed98089b",
        "id": "b0WxAch2kC7Y"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see, we removed most of the background."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "7cc27f81-9c2c-459c-8b35-ef5b9be2d181",
        "_uuid": "6489aa4c23ae6c6e07c07e7555d09242cf7413db",
        "id": "qyoKl0p_YzSi"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2. Normalize input\n",
        "\n",
        "Now set the values of input from [0...255] to [0...1] (RGB color-space encode colors with numbers [0...255]). CNN will be faster train if we use [0...1] input"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b8010cb8-e9c8-4f88-a660-071c8b91b8ba",
        "_uuid": "e831049e1526c3732ce81a4a8b9521e48ad2ac2b",
        "collapsed": true,
        "id": "9P7UIelKYzSi",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "clearTrainImg = clearTrainImg / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a184fb96-476c-42e2-9012-b0552922efa7",
        "_uuid": "00334d8001013329d0ea54ec23206fbcda0c7276",
        "id": "PjtJmDJ6YzSl"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3. Categories labels\n",
        "\n",
        "Now we encode image labels. Labels are 12 string names, so we could create classes array with this names, for example ['Black-grass' 'Charlock' 'Cleavers' 'Common Chickweed' 'Common wheat' 'Fat Hen' 'Loose Silky-bent' 'Maize' 'Scentless Mayweed' 'Shepherds Purse' 'Small-flowered Cranesbill' 'Sugar beet'] and encode every label by position in this array. For example 'Charlock' -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0].\n",
        "\n",
        "We need to encode all labels in this way."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1e17fd46-a7b4-4470-b28b-215a39a206e0",
        "_uuid": "61f289328cdf2ffd1bd1c66f91e3b8e8514d069d",
        "id": "jHz3WJhrYzSm",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Encode labels and create classes\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(trainLabel[0])\n",
        "print(\"Classes: \" + str(le.classes_))\n",
        "encodeTrainLabels = le.transform(trainLabel[0])\n",
        "\n",
        "# Make labels categorical\n",
        "clearTrainLabel = np_utils.to_categorical(encodeTrainLabels)\n",
        "num_clases = clearTrainLabel.shape[1]\n",
        "print(\"Number of classes: \" + str(num_clases))\n",
        "\n",
        "# Plot of label types numbers\n",
        "trainLabel[0].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f01b8fd7-cd51-4754-bb74-6101c0920208",
        "_uuid": "49e51b6b50ea58102bfa26effb2f733638b9b3e4",
        "id": "q5yo5N_0kC7Y"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see, we have different counts of images of different species. So, data is unbalanced"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "df1f4d6c-726b-4c3e-8f8c-d344f942ff9d",
        "_uuid": "01a4d08cb1fede2162d58589bd4d2ce181bea275",
        "id": "PBsNYbfNYzSq"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='section3'></a>\n",
        "## 3. Model\n",
        "\n",
        "### 3.1. Split dataset\n",
        "Split data on training and validation set. 10% of data became the validation set\n",
        "\n",
        "Our data is unbalanced, so for avoide inaccurate evaluation of model set stratify=clearTrainLabel"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "6b14bc73-6e8d-4ae9-98fb-37b692b75103",
        "_uuid": "a92bd39afd9769d7ea9e793ee85a505f3c19fdd5",
        "collapsed": true,
        "id": "EJy83dSEYzSr",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(clearTrainImg, clearTrainLabel,\n",
        "                                                test_size=0.1, random_state=seed,\n",
        "                                                stratify = clearTrainLabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "09d0ad71-0bb2-4b6b-b015-8be9600ddabd",
        "_uuid": "8bb49cf39cc87436d34d6d831d55c53ac10d682e",
        "id": "nvjJmQ9nYzSu"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2. Data generator\n",
        "To avoide overfitting we need to create image generator which will randomly rotate, zoom, shift and flip image during the fitting of the model.\n",
        "\n",
        "* Set random rotation from 0 to 180 degrees\n",
        "* Set random zoom at 0.1\n",
        "* Set random shifting at 0.1\n",
        "* Set horisontal and vertical flips"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "6ed3e088-f882-4536-b889-1007979830c9",
        "_uuid": "53d859526c2edc7b0063f07592b0c45b05cf1695",
        "collapsed": true,
        "id": "ftwKbrJ5YzSv",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=180,  # randomly rotate images in the range\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images horizontally\n",
        "        vertical_flip=True  # randomly flip images vertically\n",
        "    )\n",
        "datagen.fit(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bc368c34-d8a7-4578-b1a9-561534fe4a04",
        "_uuid": "9e98b9806e9d0ec27afaa768eb40406ec7acdd8f",
        "id": "qq1DW3AQYzS0"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3. Create model\n",
        "\n",
        "For creation model i used Keras Sequential.\n",
        "\n",
        "I created model with six convolutional layers and three fully-connected layers in the end. First two convolutional layers have 64 filters, next 128 filters and the last two layers have 256 filters. After each pair of convolution layers model have max pooling layer. Also, to reduce overfitting after each pair of convolution layers we use dropout layer (10% between convolutional layers and 50% between fully connect layers) and between each layer we use batch normalization layer.\n",
        "\n",
        "In the end i used three fully-connected layers for classifing. In the last layer the neural net outputs destribution of probability for each of 12 classes."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "d3fdb265-6af1-420f-a5af-6d507d7814d9",
        "_uuid": "f078274c7eeb7935aaed1fad4d45b9f1a93a0a64",
        "id": "iIM5G4UrYzS3",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "numpy.random.seed(seed)  # Fix seed\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(ScaleTo, ScaleTo, 3), activation='relu'))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_clases, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f7936cad-c644-4cb5-8e15-045ec161fe61",
        "_uuid": "1afe9e3f61fa7dc5f354bd16c73c73e0c6d6875e",
        "id": "PXjrtevDYzS8"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.4. Fit model\n",
        "Here we'll train our model. Firstly, we set several callbacks. First callback reduce model learning rate. With high learning rate model quiker is the convergance, however with high learning rate the model could fall into a local minimum. So, we will decreace the learning rate at the process of fitting. We will reduce learning rate if the accuracy is not improved after for three epoch. Other two callbacks save best and last weights of model.\n",
        "\n",
        "We won't train model on kaggle kernel, becauce it is too long process, so i comment the lines of code with fitting."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0d46cea4-c01c-42f6-a615-500ccaa6abbb",
        "_kg_hide-input": false,
        "_uuid": "eb1fffe45e463ed1e8951a7293f2fea14c08811a",
        "collapsed": true,
        "id": "cy4S_8g7YzS9",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "# learning rate reduction\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.4,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# checkpoints\n",
        "filepath=\"drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "filepath=\"drive/DataScience/PlantReco/weights.last_auto4.hdf5\"\n",
        "checkpoint_all = ModelCheckpoint(filepath, monitor='val_acc',\n",
        "                                 verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "# all callbacks\n",
        "callbacks_list = [checkpoint, learning_rate_reduction, checkpoint_all]\n",
        "\n",
        "# fit model\n",
        "# hist = model.fit_generator(datagen.flow(trainX, trainY, batch_size=75),\n",
        "#                            epochs=35, validation_data=(testX, testY),\n",
        "#                            steps_per_epoch=trainX.shape[0], callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d10e22b5-a811-4cbf-97b8-f85968614605",
        "_uuid": "62cc51ad9ca7f7fc43b77b62dfe1238b9f100e6e",
        "id": "YdftQOFBkC7Z"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='section4'></a>\n",
        "## 4. Evaluate model\n",
        "### 4.1. Load model from file\n",
        "\n",
        "Here we load the weights of best-fitting model from file (i used kaggle dataset with weights of model, which i trained earlier). Also i load from Data.npz training and validation data sets, on which model was fitting for evaluating of model accuracy."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "fafb1f53-33a1-4c61-be15-61d0091a5a18",
        "_uuid": "d642cde459cddcbc8c57a21289fab8f423a34f5b",
        "id": "TKkO1FHuYzTK",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(\"../input/plantrecomodels/weights.best_17-0.96.hdf5\")\n",
        "\n",
        "data = np.load(\"../input/plantrecomodels/Data.npz\")\n",
        "d = dict(zip((\"trainX\",\"testX\",\"trainY\", \"testY\"), (data[k] for k in data)))\n",
        "trainX = d['trainX']\n",
        "testX = d['testX']\n",
        "trainY = d['trainY']\n",
        "testY = d['testY']\n",
        "\n",
        "print(model.evaluate(trainX, trainY))  # Evaluate on train set\n",
        "print(model.evaluate(testX, testY))  # Evaluate on test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8c99fb9cc81bf27437b9734daad19150c2390ab7",
        "id": "NXS5eqRqkC7Z"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2. Confusion matrix\n",
        "\n",
        "A good way to look at model errors."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af292cea90fb8cd98e6d6b0eff8cc6b8eeeacaba",
        "id": "vViY6BlvkC7Z"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "predY = model.predict(testX)\n",
        "predYClasses = np.argmax(predY, axis = 1)\n",
        "trueY = np.argmax(testY, axis = 1)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMTX = confusion_matrix(trueY, predYClasses)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusionMTX, classes = le.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0826f50f-db77-4063-884e-84b1105af8cb",
        "_uuid": "39f7431849e766e2ad26b293f510f52f5196269b",
        "id": "MylCVy4_YzTD"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.3. Get results\n",
        "\n",
        "And finnaly we get the result of prediction on test data."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "86687bf4-6e50-463e-a80c-54a67cae4211",
        "_uuid": "fbcc8ed936331ad2ed68e61169dc17f0f8400392",
        "collapsed": true,
        "id": "Xfg3GA69YzTE",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "path = '../input/plant-seedlings-classification/test/*.png'\n",
        "files = glob(path)\n",
        "\n",
        "testImg = []\n",
        "testId = []\n",
        "j = 1\n",
        "num = len(files)\n",
        "\n",
        "# Obtain images and resizing, obtain labels\n",
        "for img in files:\n",
        "    print(\"Obtain images: \" + str(j) + \"/\" + str(num), end='\\r')\n",
        "    testId.append(img.split('/')[-1])  # Images id's\n",
        "    testImg.append(cv2.resize(cv2.imread(img), (ScaleTo, ScaleTo)))\n",
        "    j += 1\n",
        "\n",
        "testImg = np.asarray(testImg)  # Train images set\n",
        "\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(testImg[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0ab0df7d-3775-4ea5-945a-f6a6b2c488b3",
        "_uuid": "533e370a65ec08291b1b476b9de9d063adb442e5",
        "collapsed": true,
        "id": "p_gDyP28YzTP",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "clearTestImg = []\n",
        "examples = []; getEx = True\n",
        "for img in testImg:\n",
        "    # Use gaussian blur\n",
        "    blurImg = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "    # Convert to HSV image\n",
        "    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Create mask (parameters - green color range)\n",
        "    lower_green = (25, 40, 50)\n",
        "    upper_green = (75, 255, 255)\n",
        "    mask = cv2.inRange(hsvImg, lower_green, upper_green)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Create bool mask\n",
        "    bMask = mask > 0\n",
        "\n",
        "    # Apply the mask\n",
        "    clear = np.zeros_like(img, np.uint8)  # Create empty image\n",
        "    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n",
        "\n",
        "    clearTestImg.append(clear)  # Append image without backgroung\n",
        "\n",
        "    # Show examples\n",
        "    if getEx:\n",
        "        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n",
        "        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image\n",
        "        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image\n",
        "        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n",
        "        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n",
        "        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n",
        "        getEx = False\n",
        "\n",
        "clearTestImg = np.asarray(clearTestImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "57a4f87d-c01a-4361-97b1-e304d12011fa",
        "_uuid": "1696af0fda008ff58ecffc5aacedd01ec63fa8c4",
        "collapsed": true,
        "trusted": true,
        "id": "4wewr9I8kC7Z"
      },
      "cell_type": "code",
      "source": [
        "# Show sample result\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(clearTestImg[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e70bc2aa-ed88-4979-8b25-eb10d11da478",
        "_uuid": "2abe8c490cdbae62889499b515141127f191499c",
        "collapsed": true,
        "trusted": true,
        "id": "9s9FqLxLkC7Z"
      },
      "cell_type": "code",
      "source": [
        "clearTestImg = clearTestImg / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "afc1253d-fca1-42da-ac34-d416ed7d416b",
        "_uuid": "059698296ec62ee33519102206f6c19ddad48b6c",
        "collapsed": true,
        "trusted": true,
        "id": "0fFM0i75kC7Z"
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(clearTestImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "72ba3a09-643e-4eb5-ac1a-8b388c53e10e",
        "_uuid": "c352558464a0f6aade5852d5e6fe3479b14425fc",
        "collapsed": true,
        "trusted": true,
        "id": "XvKp4RXEkC7Z"
      },
      "cell_type": "code",
      "source": [
        "# Write result to file\n",
        "predNum = np.argmax(pred, axis=1)\n",
        "predStr = le.classes_[predNum]\n",
        "\n",
        "res = {'file': testId, 'species': predStr}\n",
        "res = pd.DataFrame(res)\n",
        "res.to_csv(\"res.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "name": "Plant Seedlings with CNN and Image Processing",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}